{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“˜ Ultimate EDA & Feature Engineering Playbook\n",
                "\n",
                "## Overview\n",
                "This notebook is a comprehensive guide to Exploratory Data Analysis (EDA) and Feature Engineering.\n",
                "It is designed to be a **template** you can plug any dataset into.\n",
                "\n",
                "### ðŸ“š Table of Contents\n",
                "1. **Environment Setup**: Libraries and Configuration\n",
                "2. **Data Loading**: Ingestion and Sanity Checks\n",
                "3. **Initial Exploration**: Structure, Types, and Summary Stats\n",
                "4. **Data Cleaning**: Missing Values and Duplicates\n",
                "5. **Univariate Analysis**: Numerical and Categorical Distributions\n",
                "6. **Bivariate Analysis**: Correlations and Relationships\n",
                "7. **Multivariate Analysis**: Pairplots and Interactions\n",
                "8. **Feature Engineering**: Creation, Transformation, and Encoding\n",
                "9. **Preprocessing**: Scaling and Splitting\n",
                "10. **Conclusion**: Summary of Findings\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup\n",
                "Importing necessary libraries for manipulation and visualization.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "\n",
                "# Configuration\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "sns.set_theme(style='whitegrid')\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "%matplotlib inline\n",
                "print('Libraries Imported Successfully')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading\n",
                "Load your dataset here. For this playbook, we will generate a synthetic dataset to demonstrate functionality.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generating a robust synthetic dataset\n",
                "from sklearn.datasets import make_classification\n",
                "\n",
                "# Create synthetic data\n",
                "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, \n",
                "                           n_redundant=5, n_classes=2, random_state=42)\n",
                "\n",
                "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(20)])\n",
                "df['target'] = y\n",
                "\n",
                "# Injecting some messiness for practice (Missing values, Categorical columns)\n",
                "import random\n",
                "\n",
                "df['category_A'] = np.random.choice(['Red', 'Blue', 'Green'], df.shape[0])\n",
                "df['category_B'] = np.random.choice(['Low', 'Medium', 'High'], df.shape[0])\n",
                "df.loc[::10, 'feature_0'] = np.nan  # Inject missing values\n",
                "df.loc[::20, 'category_A'] = np.nan # Inject missing values in categorical\n",
                "\n",
                "print(f'Dataset Shape: {df.shape}')\n",
                "df.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initial Exploration\n",
                "Understanding the basic structure of the data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.1 Data Types and Info\n",
                "df.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.2 Summary Statistics (Numerical)\n",
                "df.describe().T\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3.3 Summary Statistics (Categorical)\n",
                "df.describe(include=['object']).T\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Cleaning\n",
                "Identifying and handling Nulls and Duplicates.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.1 Missing Value Analysis\n",
                "missing = df.isnull().sum()\n",
                "missing = missing[missing > 0]\n",
                "if not missing.empty:\n",
                "    missing_percent = (missing / len(df)) * 100\n",
                "    pd.DataFrame({'Missing Count': missing, 'Percentage': missing_percent})\n",
                "else:\n",
                "    print('No missing values found')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.2 Visualizing Missing Data\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
                "plt.title('Missing Value Heatmap')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.3 Handling Missing Values\n",
                "# Strategy: Impute Numerical with Median, Categorical with Mode\n",
                "\n",
                "# Numerical\n",
                "num_cols = df.select_dtypes(include=np.number).columns\n",
                "for col in num_cols:\n",
                "    df[col].fillna(df[col].median(), inplace=True)\n",
                "\n",
                "# Categorical\n",
                "cat_cols = df.select_dtypes(include='object').columns\n",
                "for col in cat_cols:\n",
                "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
                "\n",
                "print('Missing values handled.')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.4 Duplicate Removal\n",
                "duplicates = df.duplicated().sum()\n",
                "print(f'Duplicates found: {duplicates}')\n",
                "df.drop_duplicates(inplace=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Univariate Analysis\n",
                "Analyzing features individually.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.1 Numerical Distributions (Histograms + KDE)\n",
                "features_to_plot = ['feature_0', 'feature_1', 'feature_2', 'feature_3']\n",
                "\n",
                "plt.figure(figsize=(15, 10))\n",
                "for i, col in enumerate(features_to_plot, 1):\n",
                "    plt.subplot(2, 2, i)\n",
                "    sns.histplot(df[col], kde=True, bins=30)\n",
                "    plt.title(f'Distribution of {col}')\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.2 Boxplots for Outlier Detection\n",
                "plt.figure(figsize=(15, 6))\n",
                "sns.boxplot(data=df[features_to_plot], orient='h')\n",
                "plt.title('Boxplots of Selected Features')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5.3 Categorical Frequency Plots\n",
                "plt.figure(figsize=(12, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "sns.countplot(x='category_A', data=df)\n",
                "plt.title('Frequency of Category A')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "sns.countplot(x='category_B', data=df)\n",
                "plt.title('Frequency of Category B')\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Bivariate Analysis\n",
                "Analyzing relationships between variables and the target.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.1 Numerical Feature vs Target (Box Plot)\n",
                "# Assuming 'target' is categorical/binary for this visualization\n",
                "plt.figure(figsize=(15, 6))\n",
                "sns.boxplot(x='target', y='feature_0', data=df)\n",
                "plt.title('Feature 0 Distribution by Target')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.2 Correlation Heatmap\n",
                "plt.figure(figsize=(18, 14))\n",
                "corr = df.select_dtypes(include=np.number).corr()\n",
                "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
                "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
                "plt.title('Correlation Matrix')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6.3 Categorical vs Target (Crosstab)\n",
                "ct = pd.crosstab(df['category_A'], df['target'], normalize='index')\n",
                "ct.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
                "plt.title('Category A vs Target (Stacked Bar)')\n",
                "plt.ylabel('Proportion')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Multivariate Analysis\n",
                "Complex interactions between multiple variables.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7.1 Pairplot of key features\n",
                "subset_cols = ['feature_0', 'feature_1', 'feature_2', 'target']\n",
                "sns.pairplot(df[subset_cols], hue='target', palette='husl')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Feature Engineering\n",
                "Creating new features and transforming existing ones.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8.1 Interaction Features\n",
                "# Example: Creating a ratio of two features\n",
                "df['feature_0_1_ratio'] = df['feature_0'] / (df['feature_1'] + 0.001)\n",
                "print('Created interaction feature: feature_0_1_ratio')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8.2 Binning Numerical Variables\n",
                "df['feature_0_binned'] = pd.qcut(df['feature_0'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
                "print('Created binned feature: feature_0_binned')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8.3 Encoding Categorical Variables\n",
                "# One-Hot Encoding\n",
                "df_encoded = pd.get_dummies(df, columns=['category_A', 'category_B', 'feature_0_binned'], drop_first=True)\n",
                "print('Performed One-Hot Encoding')\n",
                "df_encoded.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Preprocessing for Machine Learning\n",
                "Scaling and Splitting the data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Separating Target and Features\n",
                "X = df_encoded.drop('target', axis=1)\n",
                "y = df_encoded['target']\n",
                "\n",
                "# Train Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Scaling\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f'Train Shape: {X_train_scaled.shape}')\n",
                "print(f'Test Shape: {X_test_scaled.shape}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Practice Exercises\n",
                "Try these to test your understanding.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1: Find the feature with the highest correlation to the target (excluding itself).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 2: Create a Violin Plot for 'feature_5' against 'category_A'.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 3: Use Log Transformation on 'feature_0' and plot the before/after distribution.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
